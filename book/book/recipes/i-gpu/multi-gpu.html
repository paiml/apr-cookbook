<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Multi-GPU Inference - APR Cookbook - Idiomatic Rust Patterns for ML Model Deployment</title>


        <!-- Custom HTML head -->

        <meta name="description" content="Production recipes for bundling, converting, and deploying ML models using the APR format with Toyota Way quality principles">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">APR Cookbook - Idiomatic Rust Patterns for ML Model Deployment</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/paiml/apr-cookbook" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/paiml/apr-cookbook/edit/main/book/src/recipes/i-gpu/multi-gpu.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="multi-gpu-inference"><a class="header" href="#multi-gpu-inference">Multi-GPU Inference</a></h1>
<blockquote>
<p><strong>Status</strong>: Verified | <strong>Idempotent</strong>: Yes | <strong>Coverage</strong>: 95%+</p>
</blockquote>
<h2 id="run-command"><a class="header" href="#run-command">Run Command</a></h2>
<pre><code class="language-bash">cargo run --example gpu_multi_gpu_inference
</code></pre>
<h2 id="code"><a class="header" href="#code">Code</a></h2>
<pre><code class="language-rust ignore">//! # Recipe: Multi-GPU Inference
//!
//! **Category**: GPU Acceleration
//! **Isolation Level**: Full
//! **Idempotency**: Guaranteed
//! **Dependencies**: None (default features)
//!
//! ## QA Checklist
//! 1. [x] `cargo run` succeeds (Exit Code 0)
//! 2. [x] `cargo test` passes
//! 3. [x] Deterministic output (Verified)
//! 4. [x] No temp files leaked
//! 5. [x] Memory usage stable
//! 6. [x] WASM compatible (N/A)
//! 7. [x] Clippy clean
//! 8. [x] Rustfmt standard
//! 9. [x] No `unwrap()` in logic
//! 10. [x] Proptests pass (100+ cases)
//!
//! ## Learning Objective
//! Distribute inference across multiple GPUs.
//!
//! ## Run Command
//! ```bash
//! cargo run --example gpu_multi_gpu_inference
//! ```

use apr_cookbook::prelude::*;
use serde::{Deserialize, Serialize};

fn main() -&gt; Result&lt;()&gt; {
    let mut ctx = RecipeContext::new("gpu_multi_gpu_inference")?;

    println!("=== Recipe: {} ===", ctx.name());
    println!("Multi-GPU inference distribution");
    println!();

    // Detect GPUs
    let gpus = detect_gpus();
    ctx.record_metric("gpu_count", gpus.len() as i64);

    println!("Detected GPUs:");
    for gpu in &amp;gpus {
        println!("  GPU {}: {} ({}GB)", gpu.id, gpu.name, gpu.memory_gb);
    }
    println!();

    // Configure multi-GPU strategy
    let strategies = vec![
        DistributionStrategy::DataParallel,
        DistributionStrategy::PipelineParallel,
        DistributionStrategy::TensorParallel,
    ];

    // Model config
    let model_config = ModelConfig {
        total_params_b: 7.0, // 7B parameter model
        layers: 32,
        batch_size: 64,
    };

    println!(
        "Model: {:.0}B parameters, {} layers",
        model_config.total_params_b, model_config.layers
    );
    println!("Batch size: {}", model_config.batch_size);
    println!();

    println!("Strategy Comparison ({} GPUs):", gpus.len());
    println!("{:-&lt;70}", "");
    println!(
        "{:&lt;20} {:&gt;12} {:&gt;12} {:&gt;12} {:&gt;10}",
        "Strategy", "Time(ms)", "Throughput", "Efficiency", "Memory/GPU"
    );
    println!("{:-&lt;70}", "");

    let mut results = Vec::new();
    for strategy in &amp;strategies {
        let result = benchmark_strategy(&amp;gpus, &amp;model_config, *strategy)?;
        results.push(result.clone());

        println!(
            "{:&lt;20} {:&gt;10.2}ms {:&gt;10.0}/s {:&gt;10.0}% {:&gt;8}GB",
            format!("{:?}", strategy),
            result.total_time_ms,
            result.throughput,
            result.efficiency * 100.0,
            result.memory_per_gpu_gb
        );
    }
    println!("{:-&lt;70}", "");

    // Best strategy
    let best = results
        .iter()
        .max_by(|a, b| {
            a.throughput
                .partial_cmp(&amp;b.throughput)
                .unwrap_or(std::cmp::Ordering::Equal)
        })
        .ok_or_else(|| CookbookError::invalid_format("No results"))?;

    ctx.record_float_metric("best_throughput", best.throughput);
    ctx.record_float_metric("best_efficiency", best.efficiency);

    println!();
    println!("Best Strategy: {:?}", best.strategy);
    println!("  Throughput: {:.0} samples/sec", best.throughput);
    println!("  Efficiency: {:.0}%", best.efficiency * 100.0);

    // Scaling analysis
    println!();
    println!("Scaling Analysis:");
    let single_gpu_throughput = benchmark_strategy(
        &amp;gpus[..1],
        &amp;model_config,
        DistributionStrategy::DataParallel,
    )?
    .throughput;
    let multi_gpu_throughput = best.throughput;
    let scaling_factor = multi_gpu_throughput / single_gpu_throughput;

    println!("  Single GPU: {:.0} samples/sec", single_gpu_throughput);
    println!(
        "  {} GPUs: {:.0} samples/sec",
        gpus.len(),
        multi_gpu_throughput
    );
    println!(
        "  Scaling factor: {:.2}x (ideal: {}x)",
        scaling_factor,
        gpus.len()
    );

    // Save results
    let results_path = ctx.path("multi_gpu_benchmark.json");
    save_results(&amp;results_path, &amp;results)?;
    println!();
    println!("Results saved to: {:?}", results_path);

    Ok(())
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct GpuDevice {
    id: u32,
    name: String,
    memory_gb: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ModelConfig {
    total_params_b: f64,
    layers: u32,
    batch_size: u32,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
enum DistributionStrategy {
    DataParallel,
    PipelineParallel,
    TensorParallel,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct BenchmarkResult {
    strategy: DistributionStrategy,
    total_time_ms: f64,
    throughput: f64,
    efficiency: f64,
    memory_per_gpu_gb: u32,
}

fn detect_gpus() -&gt; Vec&lt;GpuDevice&gt; {
    // Simulated 4-GPU setup
    (0..4)
        .map(|id| GpuDevice {
            id,
            name: format!("GPU {} (Simulated)", id),
            memory_gb: 24,
        })
        .collect()
}

fn benchmark_strategy(
    gpus: &amp;[GpuDevice],
    model: &amp;ModelConfig,
    strategy: DistributionStrategy,
) -&gt; Result&lt;BenchmarkResult&gt; {
    let gpu_count = gpus.len() as f64;

    // Base time for single GPU
    let base_time_ms = model.total_params_b * 10.0 * f64::from(model.batch_size) / 1000.0;

    // Strategy-specific performance characteristics
    let (speedup, _overhead, memory_factor) = match strategy {
        DistributionStrategy::DataParallel =&gt; {
            // Good scaling but communication overhead
            let overhead = 1.0 + 0.1 * (gpu_count - 1.0);
            (gpu_count / overhead, overhead, 1.0)
        }
        DistributionStrategy::PipelineParallel =&gt; {
            // Linear memory scaling but bubble overhead
            let bubble_overhead = 1.0 + (gpu_count - 1.0) / f64::from(model.layers);
            (
                gpu_count / bubble_overhead,
                bubble_overhead,
                1.0 / gpu_count,
            )
        }
        DistributionStrategy::TensorParallel =&gt; {
            // Best for large models but high communication
            let comm_overhead = 1.0 + 0.15 * (gpu_count - 1.0);
            (gpu_count / comm_overhead, comm_overhead, 1.0 / gpu_count)
        }
    };

    let total_time = base_time_ms / speedup;
    let throughput = (f64::from(model.batch_size) / total_time) * 1000.0;
    let efficiency = speedup / gpu_count;

    let base_memory = (model.total_params_b * 2.0) as u32; // ~2GB per B params
    let memory_per_gpu = ((f64::from(base_memory) * memory_factor) as u32).max(1);

    Ok(BenchmarkResult {
        strategy,
        total_time_ms: total_time,
        throughput,
        efficiency,
        memory_per_gpu_gb: memory_per_gpu,
    })
}

fn save_results(path: &amp;std::path::Path, results: &amp;[BenchmarkResult]) -&gt; Result&lt;()&gt; {
    let json = serde_json::to_string_pretty(results)
        .map_err(|e| CookbookError::Serialization(e.to_string()))?;
    std::fs::write(path, json)?;
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_detect_gpus() {
        let gpus = detect_gpus();
        assert_eq!(gpus.len(), 4);
    }

    #[test]
    fn test_data_parallel() {
        let gpus = detect_gpus();
        let model = ModelConfig {
            total_params_b: 7.0,
            layers: 32,
            batch_size: 32,
        };

        let result = benchmark_strategy(&amp;gpus, &amp;model, DistributionStrategy::DataParallel).unwrap();

        assert!(result.throughput &gt; 0.0);
        assert!(result.efficiency &gt; 0.0 &amp;&amp; result.efficiency &lt;= 1.0);
    }

    #[test]
    fn test_pipeline_parallel_memory() {
        let gpus = detect_gpus();
        let model = ModelConfig {
            total_params_b: 7.0,
            layers: 32,
            batch_size: 32,
        };

        let data_parallel =
            benchmark_strategy(&amp;gpus, &amp;model, DistributionStrategy::DataParallel).unwrap();
        let pipeline =
            benchmark_strategy(&amp;gpus, &amp;model, DistributionStrategy::PipelineParallel).unwrap();

        // Pipeline parallel should use less memory per GPU
        assert!(pipeline.memory_per_gpu_gb &lt;= data_parallel.memory_per_gpu_gb);
    }

    #[test]
    fn test_more_gpus_more_throughput() {
        let model = ModelConfig {
            total_params_b: 7.0,
            layers: 32,
            batch_size: 32,
        };

        let gpus_2: Vec&lt;_&gt; = detect_gpus().into_iter().take(2).collect();
        let gpus_4 = detect_gpus();

        let result_2 =
            benchmark_strategy(&amp;gpus_2, &amp;model, DistributionStrategy::DataParallel).unwrap();
        let result_4 =
            benchmark_strategy(&amp;gpus_4, &amp;model, DistributionStrategy::DataParallel).unwrap();

        assert!(result_4.throughput &gt; result_2.throughput);
    }

    #[test]
    fn test_deterministic() {
        let gpus = detect_gpus();
        let model = ModelConfig {
            total_params_b: 7.0,
            layers: 32,
            batch_size: 32,
        };

        let r1 = benchmark_strategy(&amp;gpus, &amp;model, DistributionStrategy::TensorParallel).unwrap();
        let r2 = benchmark_strategy(&amp;gpus, &amp;model, DistributionStrategy::TensorParallel).unwrap();

        assert_eq!(r1.throughput, r2.throughput);
    }

    #[test]
    fn test_save_results() {
        let ctx = RecipeContext::new("test_multi_gpu_save").unwrap();
        let path = ctx.path("results.json");

        let results = vec![BenchmarkResult {
            strategy: DistributionStrategy::DataParallel,
            total_time_ms: 10.0,
            throughput: 100.0,
            efficiency: 0.9,
            memory_per_gpu_gb: 12,
        }];

        save_results(&amp;path, &amp;results).unwrap();
        assert!(path.exists());
    }
}

#[cfg(test)]
mod proptests {
    use super::*;
    use proptest::prelude::*;

    proptest! {
        #![proptest_config(ProptestConfig::with_cases(100))]

        #[test]
        fn prop_efficiency_bounded(batch in 1u32..128) {
            let gpus = detect_gpus();
            let model = ModelConfig {
                total_params_b: 7.0,
                layers: 32,
                batch_size: batch,
            };

            for strategy in [
                DistributionStrategy::DataParallel,
                DistributionStrategy::PipelineParallel,
                DistributionStrategy::TensorParallel,
            ] {
                let result = benchmark_strategy(&amp;gpus, &amp;model, strategy).unwrap();
                prop_assert!(result.efficiency &gt; 0.0);
                prop_assert!(result.efficiency &lt;= 1.0);
            }
        }

        #[test]
        fn prop_throughput_positive(batch in 1u32..64) {
            let gpus = detect_gpus();
            let model = ModelConfig {
                total_params_b: 7.0,
                layers: 32,
                batch_size: batch,
            };

            let result = benchmark_strategy(&amp;gpus, &amp;model, DistributionStrategy::DataParallel).unwrap();
            prop_assert!(result.throughput &gt; 0.0);
        }
    }
}</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../recipes/i-gpu/tensor-core.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../../recipes/i-gpu/memory-management.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../recipes/i-gpu/tensor-core.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../../recipes/i-gpu/memory-management.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>

        <script src="../../ace.js"></script>
        <script src="../../editor.js"></script>
        <script src="../../mode-rust.js"></script>
        <script src="../../theme-dawn.js"></script>
        <script src="../../theme-tomorrow_night.js"></script>

        <script src="../../elasticlunr.min.js"></script>
        <script src="../../mark.min.js"></script>
        <script src="../../searcher.js"></script>

        <script src="../../clipboard.min.js"></script>
        <script src="../../highlight.js"></script>
        <script src="../../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
